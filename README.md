# ReSampling: Time Series Forecasting with Arbitrary Temporal Resolution

A comprehensive research framework for evaluating time series forecasting models under different temporal resolutions and resampling strategies. This project explores zero-shot robustness of forecasting models when applied to data with degraded temporal resolution.

## ğŸ¯ Overview

This project investigates how time series forecasting models perform when evaluated on data with different temporal resolutions than their training data. Using sophisticated resampling techniques, we can simulate real-world scenarios where data quality degrades or collection frequencies change.

**Data Source**: [Forecasting Data Repository](https://forecastingdata.org/)

## âœ¨ Key Features

### ğŸ”„ Advanced Resampling System
- **Arbitrary resampling rates** via `scipy.signal.resample`
- **Zero-shot evaluation** of models on degraded temporal resolution
- **Multiple resampling methods**: Fourier-based and interpolation
- **Flexible temporal resolution control**: 1.0 (original), 2.0 (half samples), 0.5 (double samples)

### ğŸ§  Multiple Model Architectures
- **GRU**: Gated Recurrent Units for sequential modeling
- **DMixer**: Deep mixing architecture for time series
- **TimeMixer**: Advanced temporal mixing model
- **S5**: State Space Sequence model
- **MLP**: Simple temporal Multi-Layer Perceptron

### ğŸ”¬ Enhanced Experiment Management
- **Top-K Model Tracking**: Automatically saves only the best 3 models across sweeps
- **Hyperparameter Sweeps**: Comprehensive grid search with W&B integration
- **Real-time Model Ranking**: Thread-safe operations for concurrent runs
- **Automatic Cleanup**: Removes intermediate checkpoints to save disk space

### ğŸ“Š Comprehensive Analysis Tools
- **Rich Metrics Logging**: Detailed performance tracking
- **Cross-sweep Comparison**: Compare results across different experiments  
- **CSV Export**: Export results for further analysis
- **Command-line Utilities**: Easy-to-use analysis tools

## ğŸš€ Quick Start

### Installation

1. **Clone the repository**:
```bash
git clone <repository-url>
cd ReSampling
```

2. **Create the conda environment**:
```bash
conda env create -f env.yml
conda activate ReSampling
```

### Basic Usage

1. **Configure your experiment** in `config/default.yaml`:
```yaml
dataset: your_dataset_name
model: gru  # or dmixer, timemixer, s5, mlp
```

2. **Run a single experiment**:
```bash
cd experiments
python main.py
```

3. **Launch a hyperparameter sweep**:
```bash
python launch_sweep.py
```

4. **Test resampling effects**:
```bash
python test_sampling_rates.py
```

## ğŸ“ Project Structure

```
ReSampling/
â”œâ”€â”€ config/                    # Configuration files
â”‚   â”œâ”€â”€ default.yaml          # Main configuration
â”‚   â”œâ”€â”€ dataset/              # Dataset configurations
â”‚   â”œâ”€â”€ model/                # Model configurations
â”‚   â””â”€â”€ optimizer/            # Optimizer settings
â”œâ”€â”€ experiments/              # Main experiment scripts
â”‚   â”œâ”€â”€ main.py              # Single experiment runner
â”‚   â”œâ”€â”€ launch_sweep.py      # Sweep launcher
â”‚   â””â”€â”€ sweep_utils.py       # Sweep utilities
â”œâ”€â”€ models/                  # Model implementations
â”‚   â”œâ”€â”€ gru.py              # GRU model
â”‚   â”œâ”€â”€ dmixer.py           # DMixer model
â”‚   â”œâ”€â”€ timemixer.py        # TimeMixer model
â”‚   â”œâ”€â”€ s5_model.py         # S5 model
â”‚   â””â”€â”€ mlp.py              # MLP model
â”œâ”€â”€ extras/                 # Additional utilities
â”‚   â”œâ”€â”€ timeseriesdatamodule_resampled.py  # Resampling data module
â”‚   â”œâ”€â”€ sweep_manager.py    # Enhanced sweep management
â”‚   â”œâ”€â”€ callbacks.py        # Training callbacks
â”‚   â””â”€â”€ metrics_logging.py  # Metrics tracking
â”œâ”€â”€ datasets/               # Dataset storage
â”œâ”€â”€ logs/                  # Experiment logs
â”‚   â”œâ”€â”€ experiments/       # Single experiment logs
â”‚   â”œâ”€â”€ sweeps/           # Sweep logs
â”‚   â””â”€â”€ frequency_testing/ # Resampling test logs
â””â”€â”€ wandb/                # Weights & Biases logs
```

## ğŸ”¬ Research Focus

### Temporal Resolution Robustness
- Evaluate model performance under different sampling frequencies
- Understand degradation patterns when temporal resolution decreases
- Identify models most robust to temporal resolution changes

### Zero-Shot Transfer
- Train models on high-resolution data
- Test on lower-resolution versions without retraining
- Measure performance degradation across resolution scales

### Resampling Strategies
- Compare Fourier-based vs. interpolation resampling
- Analyze the impact of different resampling rates
- Optimize resampling parameters for minimal performance loss

## ğŸ”§ Configuration

The project uses Hydra for configuration management. Key configuration areas:

- **Dataset**: Configure data source, preprocessing, and splits
- **Model**: Select and configure model architecture
- **Training**: Set training parameters, optimizers, and schedules
- **Resampling**: Control temporal resolution and resampling methods
- **Logging**: Configure experiment tracking and output directories

## ğŸ“ˆ Experiment Types

1. **Single Experiments**: Test individual model-dataset combinations
2. **Hyperparameter Sweeps**: Comprehensive parameter exploration
3. **Frequency Testing**: Systematic resampling rate evaluation
4. **Cross-model Comparison**: Compare architectures under resampling

## ğŸ¯ Enhanced Sweep Management

The project includes a sophisticated sweep management system:

- **Automatic Top-K Selection**: Only saves the best performing models
- **Resource Optimization**: Minimal disk usage through intelligent cleanup
- **Concurrent Safety**: Thread-safe operations for parallel sweep execution
- **Rich Analytics**: Built-in tools for sweep result analysis

### Running Enhanced Sweeps

```bash
# Launch a sweep with automatic top-3 model tracking
python launch_sweep.py

# Analyze sweep results
python -m extras.sweep_manager analyze --sweep-dir logs/sweeps/your_sweep

# Export results to CSV
python -m extras.sweep_manager export --sweep-dir logs/sweeps/your_sweep --output results.csv
```

## ğŸ“Š Metrics and Analysis

The framework tracks comprehensive metrics:

- **Forecast Accuracy**: MAE, MSE, RMSE, MAPE
- **Temporal Robustness**: Performance across resampling rates
- **Model Efficiency**: Training time, memory usage, convergence
- **Zero-shot Transfer**: Original vs. resampled performance ratios

## ğŸ¤ Contributing

This is a research project focused on time series forecasting robustness. Contributions related to:
- New model architectures
- Novel resampling strategies  
- Enhanced evaluation metrics
- Dataset integrations

are welcome!

## ğŸ“„ License

[Add your license information here]

## ğŸ™ Acknowledgments

- Data source: [Forecasting Data Repository](https://forecastingdata.org/)
- Built with PyTorch Lightning, Hydra, and Weights & Biases
- Uses TSL (Time Series Library) for data handling